---
http_interactions:
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4o-mini","messages":[{"role":"system","content":"      Your
        input schema fields are:\n        ```json\n         {\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"type\":\"object\",\"properties\":{\"question\":{\"type\":\"string\",\"description\":\"A
        question to answer\"}},\"required\":[\"question\"]}\n        ```\n      Your
        output schema fields are:\n        ```json\n          {\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"type\":\"object\",\"properties\":{\"answer\":{\"type\":\"string\",\"description\":\"A
        helpful answer to the question\"},\"reasoning\":{\"type\":\"string\",\"description\":\"Step
        by step reasoning process\"}},\"required\":[\"answer\",\"reasoning\"]}\n        ````\n      \n      All
        interactions will be structured in the following way, with the appropriate
        values filled in.\n\n      ## Input values\n        ```json\n         {input_values}\n        ```  \n      ##
        Output values\n      Respond exclusively with the output schema fields in
        the json block below.\n        ```json\n          {output_values}\n        ```\n      \n      In
        adhering to this structure, your objective is: Answer questions accurately
        and helpfully Think step by step.\n\n"},{"role":"user","content":"        ##
        Input Values\n        ```json\n        {\"question\":\"What is 2+2?\"}\n        ```     \n        \n        Respond
        with the corresponding output schema fields wrapped in a ```json ``` block,
        \n         starting with the heading `## Output values`.\n"}],"temperature":0.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - Ruby
      X-Stainless-Arch:
      - arm64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - MacOS
      X-Stainless-Package-Version:
      - 0.9.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.3.6
      Content-Type:
      - application/json
      Authorization:
      - Bearer <OPENAI_API_KEY>
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '1525'
  response:
    status:
      code: 200
      message: OK
    headers:
      Date:
      - Fri, 27 Jun 2025 16:11:26 GMT
      Content-Type:
      - application/json
      Transfer-Encoding:
      - chunked
      Connection:
      - keep-alive
      Access-Control-Expose-Headers:
      - X-Request-ID
      Openai-Organization:
      - user-ftp1nrq85er9xnlu0la8snte
      Openai-Processing-Ms:
      - '3173'
      Openai-Version:
      - '2020-10-01'
      X-Envoy-Upstream-Service-Time:
      - '3177'
      X-Ratelimit-Limit-Requests:
      - '10000'
      X-Ratelimit-Limit-Tokens:
      - '200000'
      X-Ratelimit-Remaining-Requests:
      - '9998'
      X-Ratelimit-Remaining-Tokens:
      - '199667'
      X-Ratelimit-Reset-Requests:
      - 16.135s
      X-Ratelimit-Reset-Tokens:
      - 99ms
      X-Request-Id:
      - req_e777e80bfb05ec7054f6ad1ba5589bea
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - __cf_bm=bvY3F.DkVGx6o0.wW0QWKq120.evCzhQP2ll0mfoUAo-1751040686-1.0.1.1-wzMos5Yc5dbYo9JOUY86QlifpQLWwUSu6T1lCi2_Mlp3yAgu1oPR3a6uRPXjmgL7PPOSm5LP.KTlqzDTKr_bsPdncEXTrnMw_sK9K91rttc;
        path=/; expires=Fri, 27-Jun-25 16:41:26 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=M4Vyiivj_EVGwAMZiV3LRpWaKGnKLEa4f.QtKdzI9qw-1751040686151-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - 956638498c13ec93-MAD
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: ASCII-8BIT
      string: |
        {
          "id": "chatcmpl-Bn5xafsbW9vCwzCosyJANshBOFn5m",
          "object": "chat.completion",
          "created": 1751040682,
          "model": "gpt-4o-mini-2024-07-18",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "## Output values\n```json\n{\n  \"answer\": \"2 + 2 equals 4.\",\n  \"reasoning\": \"To solve the equation 2 + 2, we start with the number 2. When we add another 2 to it, we count up from 2: 3 (which is 2 + 1) and then 4 (which is 2 + 2). Therefore, the result of 2 + 2 is 4.\"\n}\n```",
                "refusal": null,
                "annotations": []
              },
              "logprobs": null,
              "finish_reason": "stop"
            }
          ],
          "usage": {
            "prompt_tokens": 282,
            "completion_tokens": 101,
            "total_tokens": 383,
            "prompt_tokens_details": {
              "cached_tokens": 0,
              "audio_tokens": 0
            },
            "completion_tokens_details": {
              "reasoning_tokens": 0,
              "audio_tokens": 0,
              "accepted_prediction_tokens": 0,
              "rejected_prediction_tokens": 0
            }
          },
          "service_tier": "default",
          "system_fingerprint": "fp_34a54ae93c"
        }
  recorded_at: Fri, 27 Jun 2025 16:11:26 GMT
recorded_with: VCR 6.3.1
