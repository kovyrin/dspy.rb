---
http_interactions:
- request:
    method: post
    uri: http://localhost:11434/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"llama3.2","messages":[{"role":"user","content":"Hello, Ollama!"}],"temperature":0.0}'
    headers:
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - application/json
      User-Agent:
      - Ruby
      Host:
      - localhost:11434
      X-Stainless-Arch:
      - x64
      X-Stainless-Lang:
      - ruby
      X-Stainless-Os:
      - Linux
      X-Stainless-Package-Version:
      - 0.13.0
      X-Stainless-Runtime:
      - ruby
      X-Stainless-Runtime-Version:
      - 3.3.8
      Content-Type:
      - application/json
      Authorization:
      - Bearer ollama
      X-Stainless-Retry-Count:
      - '0'
      X-Stainless-Timeout:
      - '600.0'
      Content-Length:
      - '94'
  response:
    status:
      code: 200
      message: OK
    headers:
      Content-Type:
      - application/json
      Date:
      - Mon, 28 Jul 2025 14:21:59 GMT
      Content-Length:
      - '378'
    body:
      encoding: UTF-8
      string: '{"id":"chatcmpl-727","object":"chat.completion","created":1753712519,"model":"llama3.2","system_fingerprint":"fp_ollama","choices":[{"index":0,"message":{"role":"assistant","content":"Hello!
        It''s nice to meet you. Is there something I can help you with or would you
        like to chat?"},"finish_reason":"stop"}],"usage":{"prompt_tokens":31,"completion_tokens":25,"total_tokens":56}}

        '
  recorded_at: Mon, 28 Jul 2025 14:21:59 GMT
recorded_with: VCR 6.3.1
